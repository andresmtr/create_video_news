{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: Your input text here This is an example text to split How does it handle, longer sentences, you may ask? Let's find out!\n",
      "Length: 120\n",
      "\n",
      "Chunk: Your input text here This is an example text to split How does it handle, longer sentences, you may ask? Let's find out!\n",
      "Length: 120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from TTS.api import TTS\n",
    "from time import time\n",
    "from text_split_and import split_text_into_chunks;\n",
    "\n",
    "\n",
    "%run text_split_and.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_replacements(file_path):\n",
    "    \"\"\"Load text replacements from an Excel file.\"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    df = df[df['langua'] != 'es']\n",
    "    replacements = {}\n",
    "    for index, row in df.iterrows():\n",
    "        replacements[row['original']] = row['replace']\n",
    "    return replacements\n",
    "\n",
    "def replace_text(text, replacements):\n",
    "    \"\"\"Replace text based on a dictionary of replacements.\"\"\"\n",
    "    for original, replace in replacements.items():\n",
    "        text = text.replace(original, replace)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load replacements from Excel file\n",
    "excel_file = 'replaces_words.xlsx'\n",
    "replacements = load_replacements(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ruta donde se deben eliminar las carpetas\n",
    "output_path = 'output_en_short'\n",
    "\n",
    "# Eliminar todas las carpetas en output_path\n",
    "if os.path.exists(output_path):\n",
    "    # Iterar sobre los elementos dentro del directorio\n",
    "    for item in os.listdir(output_path):\n",
    "        item_path = os.path.join(output_path, item)\n",
    "        # Eliminar archivos\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "        # Eliminar carpetas y su contenido de forma recursiva\n",
    "        elif os.path.isdir(item_path):\n",
    "            for root, dirs, files in os.walk(item_path, topdown=False):\n",
    "                for name in files:\n",
    "                    os.remove(os.path.join(root, name))\n",
    "                for name in dirs:\n",
    "                    os.rmdir(os.path.join(root, name))\n",
    "            os.rmdir(item_path)  # Finalmente eliminar la carpeta vacÃ­a\n",
    "else:\n",
    "    print(f\"The folder {output_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que la carpeta exista despuÃ©s de eliminar su contenido\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Ruta de la carpeta de entrada con los archivos .txt\n",
    "folder_path = '/mnt/D8E84E4DE84E2A58/Env_python/Create_video_news/0_create text/text/en/shorts/'\n",
    "\n",
    "# Lista de archivos .txt en la carpeta\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "\n",
    "# Ordenar los archivos si es necesario\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andresmtr/miniconda3/envs/AndTTSCoqui/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: xtts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andresmtr/miniconda3/envs/AndTTSCoqui/lib/python3.9/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.speakers = torch.load(speaker_file_path)\n",
      "/home/andresmtr/miniconda3/envs/AndTTSCoqui/lib/python3.9/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando: 1.txt en output_en_short/1\n",
      "Chunk: Intel Arc B580 Battlemage GPU allegedly surfaces on Geekbench\n",
      "Length: 61\n",
      "\n",
      "Chunk: Blueskyâ€™s open API means anyone can scrape your data for AI training\n",
      "Length: 68\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Intel Arc B580 Battlemage GPU allegedly surfaces on Geekbench']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 3.4300506114959717\n",
      " > Real-time factor: 0.35721593735115886\n",
      "Audio generado: output_en_short/1/0.wav\n",
      " > Text splitted to sentences.\n",
      "['Blueskyâ€™s open API means anyone can scrape your data for AI training']\n",
      " > Processing time: 1.1471376419067383\n",
      " > Real-time factor: 0.22051877008686338\n",
      "Audio generado: output_en_short/1/1.wav\n",
      "Audio final guardado en: output_en_short/1/audio_final_1.wav\n",
      "Procesando: 2.txt en output_en_short/2\n",
      "Chunk: The alleged specifications of Intel's upcoming Arc B580 GPU have surfaced on Geekbench It has 20 Xe cores,\n",
      "Length: 106\n",
      "\n",
      "Chunk: 12Gigabyte of VRAM, and a boost clock of 285 GHz However, the benchmark's performance was disappointing,\n",
      "Length: 104\n",
      "\n",
      "Chunk: with the B580 scoring 78,743 points, slower than the A580\n",
      "Length: 57\n",
      "\n",
      " > Text splitted to sentences.\n",
      "[\"The alleged specifications of Intel's upcoming Arc B580 GPU have surfaced on Geekbench It has 20 Xe cores,\"]\n",
      " > Processing time: 1.9917597770690918\n",
      " > Real-time factor: 0.18768505591612597\n",
      "Audio generado: output_en_short/2/0.wav\n",
      " > Text splitted to sentences.\n",
      "[\"12Gigabyte of VRAM, and a boost clock of 285 GHz However, the benchmark's performance was disappointing,\"]\n",
      " > Processing time: 1.8347532749176025\n",
      " > Real-time factor: 0.19107680473028194\n",
      "Audio generado: output_en_short/2/1.wav\n",
      " > Text splitted to sentences.\n",
      "['with the B580 scoring 78,743 points, slower than the A580']\n",
      " > Processing time: 1.733515739440918\n",
      " > Real-time factor: 0.19067773792138362\n",
      "Audio generado: output_en_short/2/2.wav\n",
      "Audio final guardado en: output_en_short/2/audio_final_2.wav\n",
      "Procesando: 3.txt en output_en_short/3\n",
      "Chunk: There is no guarantee that users can get privacy protection, even in the Bluesky social network\n",
      "Length: 95\n",
      "\n",
      "Chunk: Be aware of the fact that anything you post publicly to Bluesky can be scraped or copied by third parties\n",
      "Length: 105\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['There is no guarantee that users can get privacy protection, even in the Bluesky social network']\n",
      " > Processing time: 1.6929478645324707\n",
      " > Real-time factor: 0.18935912473085068\n",
      "Audio generado: output_en_short/3/0.wav\n",
      " > Text splitted to sentences.\n",
      "['Be aware of the fact that anything you post publicly to Bluesky can be scraped or copied by third parties']\n",
      " > Processing time: 1.2905809879302979\n",
      " > Real-time factor: 0.206212396984515\n",
      "Audio generado: output_en_short/3/1.wav\n",
      "Audio final guardado en: output_en_short/3/audio_final_3.wav\n",
      "Procesando: 4.txt en output_en_short/4\n",
      "Chunk: Raspberry Pi is introducing a new product, the Compute Module 5\n",
      "Length: 63\n",
      "\n",
      "Chunk: These system on  module variants are more compact single board computers without any traditional ports\n",
      "Length: 102\n",
      "\n",
      "Chunk: That makes them particularly well suited for embedded applications\n",
      "Length: 66\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Raspberry Pi is introducing a new product, the Compute Module 5']\n",
      " > Processing time: 1.1196393966674805\n",
      " > Real-time factor: 0.20916402921680513\n",
      "Audio generado: output_en_short/4/0.wav\n",
      " > Text splitted to sentences.\n",
      "['These system on  module variants are more compact single board computers without any traditional ports']\n",
      " > Processing time: 1.498260498046875\n",
      " > Real-time factor: 0.19913108774914162\n",
      "Audio generado: output_en_short/4/1.wav\n",
      " > Text splitted to sentences.\n",
      "['That makes them particularly well suited for embedded applications']\n",
      " > Processing time: 1.1289842128753662\n",
      " > Real-time factor: 0.21947825763420287\n",
      "Audio generado: output_en_short/4/2.wav\n",
      "Audio final guardado en: output_en_short/4/audio_final_4.wav\n",
      "Procesando: 5.txt en output_en_short/5\n",
      "Chunk: Sonyâ€™s portable device is likely years away from launch and the company could still decide against bringing it to market,\n",
      "Length: 121\n",
      "\n",
      "ERROR: Chunk exceeds maximum length!\n",
      "\n",
      "Chunk: the people said, asking not to be named discussing private plans On the consumer side, the more of these the better\n",
      "Length: 115\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Sonyâ€™s portable device is likely years away from launch and the company could still decide against bringing it to market,']\n",
      " > Processing time: 1.4535558223724365\n",
      " > Real-time factor: 0.20555994024699992\n",
      "Audio generado: output_en_short/5/0.wav\n",
      " > Text splitted to sentences.\n",
      "['the people said, asking not to be named discussing private plans On the consumer side, the more of these the better']\n",
      " > Processing time: 1.7819597721099854\n",
      " > Real-time factor: 0.19701270043634767\n",
      "Audio generado: output_en_short/5/1.wav\n",
      "Audio final guardado en: output_en_short/5/audio_final_5.wav\n",
      "Procesando: 6.txt en output_en_short/6\n",
      "Chunk: Apple is now integrating ChatGPT for iOS with Shortcuts app\n",
      "Length: 59\n",
      "\n",
      "Chunk: This is a great improvement as the SearchGPT feature offers the best search experience\n",
      "Length: 86\n",
      "\n",
      "Chunk: We will also discuss how this integration is expected to change user interactions with Siri and other AI powered apps\n",
      "Length: 117\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Apple is now integrating ChatGPT for iOS with Shortcuts app']\n",
      " > Processing time: 1.062424659729004\n",
      " > Real-time factor: 0.22153941355561105\n",
      "Audio generado: output_en_short/6/0.wav\n",
      " > Text splitted to sentences.\n",
      "['This is a great improvement as the SearchGPT feature offers the best search experience']\n",
      " > Processing time: 1.280290126800537\n",
      " > Real-time factor: 0.2080414846123087\n",
      "Audio generado: output_en_short/6/1.wav\n",
      " > Text splitted to sentences.\n",
      "['We will also discuss how this integration is expected to change user interactions with Siri and other AI powered apps']\n",
      " > Processing time: 1.5542447566986084\n",
      " > Real-time factor: 0.19714160656468196\n",
      "Audio generado: output_en_short/6/2.wav\n",
      "Audio final guardado en: output_en_short/6/audio_final_6.wav\n",
      "Procesando: 7.txt en output_en_short/7\n",
      "Chunk: Intel's CHIPS Act funding has been reduced by over $600 million, from $85 billion to $785 billion\n",
      "Length: 97\n",
      "\n",
      "Chunk: The company plans to invest over $90 billion in the US by the end of the decade\n",
      "Length: 79\n",
      "\n",
      "Chunk: The Biden administration is committed to supporting chip manufacturers like Intel and A M D\n",
      "Length: 91\n",
      "\n",
      " > Text splitted to sentences.\n",
      "[\"Intel's CHIPS Act funding has been reduced by over $600 million, from $85 billion to $785 billion\"]\n",
      " > Processing time: 1.906557559967041\n",
      " > Real-time factor: 0.19250308721002113\n",
      "Audio generado: output_en_short/7/0.wav\n",
      " > Text splitted to sentences.\n",
      "['The company plans to invest over $90 billion in the US by the end of the decade']\n",
      " > Processing time: 1.2700386047363281\n",
      " > Real-time factor: 0.20794486778570181\n",
      "Audio generado: output_en_short/7/1.wav\n",
      " > Text splitted to sentences.\n",
      "['The Biden administration is committed to supporting chip manufacturers like Intel and A M D']\n",
      " > Processing time: 1.3956351280212402\n",
      " > Real-time factor: 0.199002551557607\n",
      "Audio generado: output_en_short/7/2.wav\n",
      "Audio final guardado en: output_en_short/7/audio_final_7.wav\n",
      "Procesando: 8.txt en output_en_short/8\n",
      "Chunk: Windows 11 update doesn't play well with some Ubisoft games Some games might become unresponsive while starting,\n",
      "Length: 112\n",
      "\n",
      "Chunk: loading or during active gameplay Users might receive a black screen\n",
      "Length: 68\n",
      "\n",
      " > Text splitted to sentences.\n",
      "[\"Windows 11 update doesn't play well with some Ubisoft games Some games might become unresponsive while starting,\"]\n",
      " > Processing time: 1.582369327545166\n",
      " > Real-time factor: 0.19330757286793562\n",
      "Audio generado: output_en_short/8/0.wav\n",
      " > Text splitted to sentences.\n",
      "['loading or during active gameplay Users might receive a black screen']\n",
      " > Processing time: 1.168445110321045\n",
      " > Real-time factor: 0.21640416848020294\n",
      "Audio generado: output_en_short/8/1.wav\n",
      "Audio final guardado en: output_en_short/8/audio_final_8.wav\n",
      "Procesando: 9.txt en output_en_short/9\n",
      "Chunk: Tencent's Sunday Dragon 3D One features a massive 11 inch display with a 120Hz refresh rate\n",
      "Length: 91\n",
      "\n",
      "Chunk: The device comes equipped with 32Gigabyte of RAM and 1Terabyte of storage,\n",
      "Length: 74\n",
      "\n",
      "Chunk: but its ergonomic design raises questions about its usability as a handheld\n",
      "Length: 75\n",
      "\n",
      " > Text splitted to sentences.\n",
      "[\"Tencent's Sunday Dragon 3D One features a massive 11 inch display with a 120Hz refresh rate\"]\n",
      " > Processing time: 1.7123196125030518\n",
      " > Real-time factor: 0.19152588799454331\n",
      "Audio generado: output_en_short/9/0.wav\n",
      " > Text splitted to sentences.\n",
      "['The device comes equipped with 32Gigabyte of RAM and 1Terabyte of storage,']\n",
      " > Processing time: 1.451200246810913\n",
      " > Real-time factor: 0.19965412200621838\n",
      "Audio generado: output_en_short/9/1.wav\n",
      " > Text splitted to sentences.\n",
      "['but its ergonomic design raises questions about its usability as a handheld']\n",
      " > Processing time: 1.1782324314117432\n",
      " > Real-time factor: 0.20666304817860615\n",
      "Audio generado: output_en_short/9/2.wav\n",
      "Audio final guardado en: output_en_short/9/audio_final_9.wav\n",
      "Se procesaron 9 archivos y se generaron carpetas correspondientes en output_en_short.\n"
     ]
    }
   ],
   "source": [
    "# Init TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    new_folder_path = os.path.join(output_path, f'{i+1}')\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "    print(f\"Procesando: {file} en {new_folder_path}\")\n",
    "\n",
    "    # Leer el contenido del archivo .txt\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text_content = f.read()\n",
    "\n",
    "    text = replace_text(text_content, replacements)\n",
    "\n",
    "    # Dividir el texto en fragmentos manejables\n",
    "    separated_input = split_text_into_chunks(text)\n",
    "\n",
    "    # Inicializar lista de clips de audio\n",
    "    all_audio_parts = []\n",
    "\n",
    "    # Generar audios por fragmento\n",
    "    for index, text in enumerate(separated_input):\n",
    "        audio_file_path = os.path.join(new_folder_path, f\"{index}.wav\")\n",
    "        wav_data = tts.tts_to_file(\n",
    "            text=text,\n",
    "            speaker_wav=\"/mnt/D8E84E4DE84E2A58/Env_python/Machine_learing_Test/0_Create_audio/data/wavs_en/complete/Sample_1.wav\",\n",
    "            language=\"en\",\n",
    "            temperature=1,\n",
    "            file_path=audio_file_path\n",
    "        )\n",
    "        print(f\"Audio generado: {audio_file_path}\")\n",
    "        torch.cuda.empty_cache()  # Liberar memoria GPU\n",
    "        audio_part, _ = torchaudio.load(audio_file_path)\n",
    "        all_audio_parts.append(audio_part)\n",
    "\n",
    "    # Concatenar todos los clips de audio\n",
    "    concatenated_audio = torch.cat(all_audio_parts, dim=-1)\n",
    "\n",
    "    # Guardar el audio concatenado\n",
    "    final_audio_path = os.path.join(new_folder_path, f\"audio_final_{i+1}.wav\")\n",
    "    torchaudio.save(final_audio_path, concatenated_audio, sample_rate=24000)\n",
    "    print(f\"Audio final guardado en: {final_audio_path}\")\n",
    "\n",
    "\n",
    "print(f\"Se procesaron {len(files)} archivos y se generaron carpetas correspondientes en {output_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AndTTSCoqui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
