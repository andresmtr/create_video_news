{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: Your input text here This is an example text to split How does it handle, longer sentences, you may ask? Let's find out!\n",
      "Length: 120\n",
      "\n",
      "Chunk: Your input text here This is an example text to split How does it handle, longer sentences, you may ask? Let's find out!\n",
      "Length: 120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from TTS.api import TTS\n",
    "from time import time\n",
    "from text_split_and import split_text_into_chunks;\n",
    "\n",
    "\n",
    "%run text_split_and.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_replacements(file_path):\n",
    "    \"\"\"Load text replacements from an Excel file.\"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    df = df[df['langua'] != 'es']\n",
    "    replacements = {}\n",
    "    for index, row in df.iterrows():\n",
    "        replacements[row['original']] = row['replace']\n",
    "    return replacements\n",
    "\n",
    "def replace_text(text, replacements):\n",
    "    \"\"\"Replace text based on a dictionary of replacements.\"\"\"\n",
    "    for original, replace in replacements.items():\n",
    "        text = text.replace(original, replace)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load replacements from Excel file\n",
    "excel_file = 'replaces_words.xlsx'\n",
    "replacements = load_replacements(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ruta donde se deben eliminar las carpetas\n",
    "output_path = 'output_en_short'\n",
    "\n",
    "# Eliminar todas las carpetas en output_path\n",
    "if os.path.exists(output_path):\n",
    "    # Iterar sobre los elementos dentro del directorio\n",
    "    for item in os.listdir(output_path):\n",
    "        item_path = os.path.join(output_path, item)\n",
    "        # Eliminar archivos\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "        # Eliminar carpetas y su contenido de forma recursiva\n",
    "        elif os.path.isdir(item_path):\n",
    "            for root, dirs, files in os.walk(item_path, topdown=False):\n",
    "                for name in files:\n",
    "                    os.remove(os.path.join(root, name))\n",
    "                for name in dirs:\n",
    "                    os.rmdir(os.path.join(root, name))\n",
    "            os.rmdir(item_path)  # Finalmente eliminar la carpeta vacÃ­a\n",
    "else:\n",
    "    print(f\"The folder {output_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que la carpeta exista despuÃ©s de eliminar su contenido\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Ruta de la carpeta de entrada con los archivos .txt\n",
    "folder_path = '/mnt/D8E84E4DE84E2A58/Env_python/Create_video_news/0_create text/text/en/shorts/'\n",
    "\n",
    "# Lista de archivos .txt en la carpeta\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "\n",
    "# Ordenar los archivos si es necesario\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_voice = '/mnt/D8E84E4DE84E2A58/Env_python/Machine_learing_Test/0_Create_audio/data/wavs_en/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andresmtr/miniconda3/envs/AndTTSCoqui/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: xtts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andresmtr/miniconda3/envs/AndTTSCoqui/lib/python3.9/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.speakers = torch.load(speaker_file_path)\n",
      "/home/andresmtr/miniconda3/envs/AndTTSCoqui/lib/python3.9/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando: 1.txt en output_en_short/1\n",
      "Chunk: Google from Alphabet shares jump 6% after Google touts 'breakthrough' quantum chip\n",
      "Length: 82\n",
      "\n",
      "Chunk: OpenAI confirms new $200 monthly subscription, ChatGPT Pro, which includes its o1 reasoning model\n",
      "Length: 97\n",
      "\n",
      "Chunk: Cyberpunk 2077 update 2 dot 2 claims to improve Arrow Lake performance by up to 33%\n",
      "Length: 83\n",
      "\n",
      "Chunk: iOS 18 dot 2 is here with Apple Intelligence image generation features\n",
      "Length: 70\n",
      "\n",
      " > Text splitted to sentences.\n",
      "[\"Google from Alphabet shares jump 6% after Google touts 'breakthrough' quantum chip\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 1.7762491703033447\n",
      " > Real-time factor: 0.26060826017505556\n",
      "Audio generado: output_en_short/1/0.wav\n",
      " > Text splitted to sentences.\n",
      "['OpenAI confirms new $200 monthly subscription, ChatGPT Pro, which includes its o1 reasoning model']\n",
      " > Processing time: 1.5948634147644043\n",
      " > Real-time factor: 0.20379426457785765\n",
      "Audio generado: output_en_short/1/1.wav\n",
      " > Text splitted to sentences.\n",
      "['Cyberpunk 2077 update 2 dot 2 claims to improve Arrow Lake performance by up to 33%']\n",
      " > Processing time: 1.6911756992340088\n",
      " > Real-time factor: 0.2006242154176524\n",
      "Audio generado: output_en_short/1/2.wav\n",
      " > Text splitted to sentences.\n",
      "['iOS 18 dot 2 is here with Apple Intelligence image generation features']\n",
      " > Processing time: 1.4669280052185059\n",
      " > Real-time factor: 0.21376865361020975\n",
      "Audio generado: output_en_short/1/3.wav\n",
      "Audio final guardado en: output_en_short/1/audio_final_1.wav\n",
      "Procesando: 2.txt en output_en_short/2\n",
      "Chunk: Alphabet shares jump 6% after Google touts 'breakthrough' quantum chip\n",
      "Length: 70\n",
      "\n",
      "Chunk: Willow uses uncertain qubits to represent numbers instead of transistors\n",
      "Length: 72\n",
      "\n",
      "Chunk: Quantum computing could be used for drug discovery, fusion energy, battery design\n",
      "Length: 81\n",
      "\n",
      " > Text splitted to sentences.\n",
      "[\"Alphabet shares jump 6% after Google touts 'breakthrough' quantum chip\"]\n",
      " > Processing time: 1.4428822994232178\n",
      " > Real-time factor: 0.21169723931572682\n",
      "Audio generado: output_en_short/2/0.wav\n",
      " > Text splitted to sentences.\n",
      "['Willow uses uncertain qubits to represent numbers instead of transistors']\n",
      " > Processing time: 1.2268891334533691\n",
      " > Real-time factor: 0.2210493642359033\n",
      "Audio generado: output_en_short/2/1.wav\n",
      " > Text splitted to sentences.\n",
      "['Quantum computing could be used for drug discovery, fusion energy, battery design']\n",
      " > Processing time: 1.3097691535949707\n",
      " > Real-time factor: 0.22560000184952742\n",
      "Audio generado: output_en_short/2/2.wav\n",
      "Audio final guardado en: output_en_short/2/audio_final_2.wav\n",
      "Procesando: 3.txt en output_en_short/3\n",
      "Chunk: OpenAI confirms new $200 monthly subscription, ChatGPT Pro Includes its o1 reasoning model o1 reasons through tasks,\n",
      "Length: 116\n",
      "\n",
      "Chunk: planning and checking its work as it goes\n",
      "Length: 41\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['OpenAI confirms new $200 monthly subscription, ChatGPT Pro Includes its o1 reasoning model o1 reasons through tasks,']\n",
      " > Processing time: 2.1517577171325684\n",
      " > Real-time factor: 0.1885301738141853\n",
      "Audio generado: output_en_short/3/0.wav\n",
      " > Text splitted to sentences.\n",
      "['planning and checking its work as it goes']\n",
      " > Processing time: 0.8981759548187256\n",
      " > Real-time factor: 0.26579315819938937\n",
      "Audio generado: output_en_short/3/1.wav\n",
      "Audio final guardado en: output_en_short/3/audio_final_3.wav\n",
      "Procesando: 4.txt en output_en_short/4\n",
      "Chunk: Mysterious A M D Strix Halo APU emerges on Geekbench Chip expected to feature up to 16 Zen 5 cores, Radeon 8600S i GPU,\n",
      "Length: 119\n",
      "\n",
      "Chunk: and 40 Compute Units\n",
      "Length: 20\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Mysterious A M D Strix Halo APU emerges on Geekbench Chip expected to feature up to 16 Zen 5 cores, Radeon 8600S i GPU,']\n",
      " > Processing time: 2.2609663009643555\n",
      " > Real-time factor: 0.18887641289425364\n",
      "Audio generado: output_en_short/4/0.wav\n",
      " > Text splitted to sentences.\n",
      "['and 40 Compute Units']\n",
      " > Processing time: 0.8368923664093018\n",
      " > Real-time factor: 0.30152739672099843\n",
      "Audio generado: output_en_short/4/1.wav\n",
      "Audio final guardado en: output_en_short/4/audio_final_4.wav\n",
      "Procesando: 5.txt en output_en_short/5\n",
      "Chunk: Cyberpunk 2077 update 2 dot 2 claims to improve Arrow Lake performance by up to 33%,\n",
      "Length: 84\n",
      "\n",
      "Chunk: theoretically matching the Ryzen 7 7800 X 3 D\n",
      "Length: 45\n",
      "\n",
      "Chunk: Update promotes a whopping 33% performance improvement on Core Ultra 200S series CPUs\n",
      "Length: 85\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Cyberpunk 2077 update 2 dot 2 claims to improve Arrow Lake performance by up to 33%,']\n",
      " > Processing time: 1.904508352279663\n",
      " > Real-time factor: 0.19644117753052998\n",
      "Audio generado: output_en_short/5/0.wav\n",
      " > Text splitted to sentences.\n",
      "['theoretically matching the Ryzen 7 7800 X 3 D']\n",
      " > Processing time: 1.3878185749053955\n",
      " > Real-time factor: 0.21971136973480737\n",
      "Audio generado: output_en_short/5/1.wav\n",
      " > Text splitted to sentences.\n",
      "['Update promotes a whopping 33% performance improvement on Core Ultra 200S series CPUs']\n",
      " > Processing time: 1.6129248142242432\n",
      " > Real-time factor: 0.20458463042823608\n",
      "Audio generado: output_en_short/5/2.wav\n",
      "Audio final guardado en: output_en_short/5/audio_final_5.wav\n",
      "Procesando: 6.txt en output_en_short/6\n",
      "Chunk: Apple has begun rolling iOS 18 dot 2 and iPadOS 18 dot2 to iPhones and iPads\n",
      "Length: 76\n",
      "\n",
      "Chunk: The updates bring with them major enhancements to the companyâ€™s suite of AI features\n",
      "Length: 84\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Apple has begun rolling iOS 18 dot 2 and iPadOS 18 dot2 to iPhones and iPads']\n",
      " > Processing time: 1.499981164932251\n",
      " > Real-time factor: 0.2121253507359937\n",
      "Audio generado: output_en_short/6/0.wav\n",
      " > Text splitted to sentences.\n",
      "['The updates bring with them major enhancements to the companyâ€™s suite of AI features']\n",
      " > Processing time: 1.4528210163116455\n",
      " > Real-time factor: 0.21461774714379747\n",
      "Audio generado: output_en_short/6/1.wav\n",
      "Audio final guardado en: output_en_short/6/audio_final_6.wav\n",
      "Procesando: 7.txt en output_en_short/7\n",
      "Chunk: Aurora is a photorealistic image generator apparently inadvertently released for the social media platform\n",
      "Length: 106\n",
      "\n",
      "Chunk: Aurora would tie in nicely with other moves made by Musk for X to expand access to Grok\n",
      "Length: 87\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Aurora is a photorealistic image generator apparently inadvertently released for the social media platform']\n",
      " > Processing time: 1.8378374576568604\n",
      " > Real-time factor: 0.19985557850022573\n",
      "Audio generado: output_en_short/7/0.wav\n",
      " > Text splitted to sentences.\n",
      "['Aurora would tie in nicely with other moves made by Musk for X to expand access to Grok']\n",
      " > Processing time: 1.387190818786621\n",
      " > Real-time factor: 0.21448696815217236\n",
      "Audio generado: output_en_short/7/1.wav\n",
      "Audio final guardado en: output_en_short/7/audio_final_7.wav\n",
      "Procesando: 8.txt en output_en_short/8\n",
      "Chunk: ChatGPT's Canvas feature is a real time editor to inspire your writing and coding projects\n",
      "Length: 90\n",
      "\n",
      "Chunk: Canvas can comment on your work if you don't want it to rewrite your text Any errors are pinpointed and identified,\n",
      "Length: 115\n",
      "\n",
      "Chunk: and the AI will suggest how to fix them\n",
      "Length: 39\n",
      "\n",
      " > Text splitted to sentences.\n",
      "[\"ChatGPT's Canvas feature is a real time editor to inspire your writing and coding projects\"]\n",
      " > Processing time: 1.4708478450775146\n",
      " > Real-time factor: 0.2125419090382143\n",
      "Audio generado: output_en_short/8/0.wav\n",
      " > Text splitted to sentences.\n",
      "[\"Canvas can comment on your work if you don't want it to rewrite your text Any errors are pinpointed and identified,\"]\n",
      " > Processing time: 1.47440767288208\n",
      " > Real-time factor: 0.20850878134331624\n",
      "Audio generado: output_en_short/8/1.wav\n",
      " > Text splitted to sentences.\n",
      "['and the AI will suggest how to fix them']\n",
      " > Processing time: 0.888730525970459\n",
      " > Real-time factor: 0.29322043478645893\n",
      "Audio generado: output_en_short/8/2.wav\n",
      "Audio final guardado en: output_en_short/8/audio_final_8.wav\n",
      "Procesando: 9.txt en output_en_short/9\n",
      "Chunk: Fornite Ballistic is a 5v5 tactical first person shooter mode One team will be tasked with planting a Rift Point Device\n",
      "Length: 119\n",
      "\n",
      "Chunk: One map and a limited selection of weapons and items\n",
      "Length: 52\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Fornite Ballistic is a 5v5 tactical first person shooter mode One team will be tasked with planting a Rift Point Device']\n",
      " > Processing time: 1.8318536281585693\n",
      " > Real-time factor: 0.19820391625233794\n",
      "Audio generado: output_en_short/9/0.wav\n",
      " > Text splitted to sentences.\n",
      "['One map and a limited selection of weapons and items']\n",
      " > Processing time: 0.9674222469329834\n",
      " > Real-time factor: 0.27404497102867786\n",
      "Audio generado: output_en_short/9/1.wav\n",
      "Audio final guardado en: output_en_short/9/audio_final_9.wav\n",
      "Se procesaron 9 archivos y se generaron carpetas correspondientes en output_en_short.\n"
     ]
    }
   ],
   "source": [
    "# Init TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    new_folder_path = os.path.join(output_path, f'{i+1}')\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "    print(f\"Procesando: {file} en {new_folder_path}\")\n",
    "\n",
    "    # Leer el contenido del archivo .txt\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text_content = f.read()\n",
    "\n",
    "    text = replace_text(text_content, replacements)\n",
    "\n",
    "    # Dividir el texto en fragmentos manejables\n",
    "    separated_input = split_text_into_chunks(text)\n",
    "\n",
    "    # Inicializar lista de clips de audio\n",
    "    all_audio_parts = []\n",
    "\n",
    "    # Generar audios por fragmento\n",
    "    for index, text in enumerate(separated_input):\n",
    "        audio_file_path = os.path.join(new_folder_path, f\"{index}.wav\")\n",
    "        wav_data = tts.tts_to_file(\n",
    "            text=text,\n",
    "            speaker_wav=[f\"{Path_voice}complete/Sample_1.wav\", f\"{Path_voice}Sample#01.wav\", f\"{Path_voice}Sample#06.wav\", f\"{Path_voice}Sample#07.wav\", f\"{Path_voice}Sample#08.wav\", f\"{Path_voice}Sample#09.wav\", f\"{Path_voice}Sample#10.wav\", f\"{Path_voice}Sample#11.wav\", f\"{Path_voice}Sample#13.wav\"],\n",
    "            language=\"en\",\n",
    "            temperature=1,\n",
    "            file_path=audio_file_path\n",
    "        )\n",
    "        print(f\"Audio generado: {audio_file_path}\")\n",
    "        torch.cuda.empty_cache()  # Liberar memoria GPU\n",
    "        audio_part, _ = torchaudio.load(audio_file_path)\n",
    "        all_audio_parts.append(audio_part)\n",
    "\n",
    "    # Concatenar todos los clips de audio\n",
    "    concatenated_audio = torch.cat(all_audio_parts, dim=-1)\n",
    "\n",
    "    # Guardar el audio concatenado\n",
    "    final_audio_path = os.path.join(new_folder_path, f\"audio_final_{i+1}.wav\")\n",
    "    torchaudio.save(final_audio_path, concatenated_audio, sample_rate=24000)\n",
    "    print(f\"Audio final guardado en: {final_audio_path}\")\n",
    "\n",
    "\n",
    "print(f\"Se procesaron {len(files)} archivos y se generaron carpetas correspondientes en {output_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AndTTSCoqui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
