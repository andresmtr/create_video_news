{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: Your input text here This is an example text to split How does it handle, longer sentences, you may ask? Let's find out!\n",
      "Length: 120\n",
      "\n",
      "Chunk: Your input text here This is an example text to split How does it handle, longer sentences, you may ask? Let's find out!\n",
      "Length: 120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from TTS.api import TTS\n",
    "from time import time\n",
    "from text_split_and import split_text_into_chunks;\n",
    "\n",
    "\n",
    "%run text_split_and.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_replacements(file_path):\n",
    "    \"\"\"Load text replacements from an Excel file.\"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    df = df[df['langua'] != 'es']\n",
    "    replacements = {}\n",
    "    for index, row in df.iterrows():\n",
    "        replacements[row['original']] = row['replace']\n",
    "    return replacements\n",
    "\n",
    "def replace_text(text, replacements):\n",
    "    \"\"\"Replace text based on a dictionary of replacements.\"\"\"\n",
    "    for original, replace in replacements.items():\n",
    "        text = text.replace(original, replace)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load replacements from Excel file\n",
    "excel_file = 'replaces_words.xlsx'\n",
    "replacements = load_replacements(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ruta donde se deben eliminar las carpetas\n",
    "output_path = 'output_en_short'\n",
    "\n",
    "# Eliminar todas las carpetas en output_path\n",
    "if os.path.exists(output_path):\n",
    "    # Iterar sobre los elementos dentro del directorio\n",
    "    for item in os.listdir(output_path):\n",
    "        item_path = os.path.join(output_path, item)\n",
    "        # Eliminar archivos\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "        # Eliminar carpetas y su contenido de forma recursiva\n",
    "        elif os.path.isdir(item_path):\n",
    "            for root, dirs, files in os.walk(item_path, topdown=False):\n",
    "                for name in files:\n",
    "                    os.remove(os.path.join(root, name))\n",
    "                for name in dirs:\n",
    "                    os.rmdir(os.path.join(root, name))\n",
    "            os.rmdir(item_path)  # Finalmente eliminar la carpeta vacÃ­a\n",
    "else:\n",
    "    print(f\"The folder {output_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que la carpeta exista despuÃ©s de eliminar su contenido\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Ruta de la carpeta de entrada con los archivos .txt\n",
    "folder_path = '/mnt/D8E84E4DE84E2A58/Env_python/Create_video_news/0_create text/text/en/shorts/'\n",
    "\n",
    "# Lista de archivos .txt en la carpeta\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "\n",
    "# Ordenar los archivos si es necesario\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_voice = '/mnt/D8E84E4DE84E2A58/Env_python/Machine_learing_Test/0_Create_audio/data/wavs_en/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andresmtr/miniconda3/envs/AndTTSCoqui/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: xtts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andresmtr/miniconda3/envs/AndTTSCoqui/lib/python3.9/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.speakers = torch.load(speaker_file_path)\n",
      "/home/andresmtr/miniconda3/envs/AndTTSCoqui/lib/python3.9/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando: 1.txt en output_en_short/1\n",
      "Chunk: Spotify Wrapped 2024 adds an AI podcast powered by Googleâ€™s NotebookLM OpenAI gets new $1\n",
      "Length: 89\n",
      "\n",
      "Chunk: 5 billion investment from SoftBank, allowing employees to sell shares in a tender offer\n",
      "Length: 87\n",
      "\n",
      "Chunk: PS5 is getting classic themes and boot sequences for its 30th anniversary\n",
      "Length: 73\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Spotify Wrapped 2024 adds an AI podcast powered by Googleâ€™s NotebookLM OpenAI gets new $1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 7.719193458557129\n",
      " > Real-time factor: 0.4000305901956922\n",
      "Audio generado: output_en_short/1/0.wav\n",
      " > Text splitted to sentences.\n",
      "['5 billion investment from SoftBank, allowing employees to sell shares in a tender offer']\n",
      " > Processing time: 1.4313678741455078\n",
      " > Real-time factor: 0.2162705680908648\n",
      "Audio generado: output_en_short/1/1.wav\n",
      " > Text splitted to sentences.\n",
      "['PS5 is getting classic themes and boot sequences for its 30th anniversary']\n",
      " > Processing time: 1.2697129249572754\n",
      " > Real-time factor: 0.21870055301921573\n",
      "Audio generado: output_en_short/1/2.wav\n",
      "Audio final guardado en: output_en_short/1/audio_final_1.wav\n",
      "Procesando: 2.txt en output_en_short/2\n",
      "Chunk: Spotify has released its annual Wrapped feature for 2024\n",
      "Length: 56\n",
      "\n",
      "Chunk: New features include a personalized AI podcast powered by Google's NotebookLM\n",
      "Length: 77\n",
      "\n",
      "Chunk: Audiobooks are also available across various markets, with a dedicated Wrapped experience for authors and publishers\n",
      "Length: 116\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Spotify has released its annual Wrapped feature for 2024']\n",
      " > Processing time: 1.2028217315673828\n",
      " > Real-time factor: 0.23383251499736202\n",
      "Audio generado: output_en_short/2/0.wav\n",
      " > Text splitted to sentences.\n",
      "[\"New features include a personalized AI podcast powered by Google's NotebookLM\"]\n",
      " > Processing time: 1.2006566524505615\n",
      " > Real-time factor: 0.23080693948366995\n",
      "Audio generado: output_en_short/2/1.wav\n",
      " > Text splitted to sentences.\n",
      "['Audiobooks are also available across various markets, with a dedicated Wrapped experience for authors and publishers']\n",
      " > Processing time: 1.8593761920928955\n",
      " > Real-time factor: 0.191786005143928\n",
      "Audio generado: output_en_short/2/2.wav\n",
      "Audio final guardado en: output_en_short/2/audio_final_2.wav\n",
      "Procesando: 3.txt en output_en_short/3\n",
      "Chunk: Gelsinger resigns after nearly four years at the helm of the chip giant\n",
      "Length: 71\n",
      "\n",
      "Chunk: He was criticized for not doing enough to compete with Samsung and other rivals\n",
      "Length: 79\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Gelsinger resigns after nearly four years at the helm of the chip giant']\n",
      " > Processing time: 1.3911123275756836\n",
      " > Real-time factor: 0.2202328175118023\n",
      "Audio generado: output_en_short/3/0.wav\n",
      " > Text splitted to sentences.\n",
      "['He was criticized for not doing enough to compete with Samsung and other rivals']\n",
      " > Processing time: 1.290032148361206\n",
      " > Real-time factor: 0.21827201405282837\n",
      "Audio generado: output_en_short/3/1.wav\n",
      "Audio final guardado en: output_en_short/3/audio_final_3.wav\n",
      "Procesando: 4.txt en output_en_short/4\n",
      "Chunk: SoftBank has invested $15 billion in OpenAI, a private AI company valued at $157 billion\n",
      "Length: 88\n",
      "\n",
      "Chunk: The investment was spurred by SoftBank's billionaire founder and CEO Masayoshi Son's interest in acquiring a larger stake in the company\n",
      "Length: 136\n",
      "\n",
      "ERROR: Chunk exceeds maximum length!\n",
      "\n",
      "Chunk: The tender offer will allow employees to sell shares at $210 each\n",
      "Length: 65\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['SoftBank has invested $15 billion in OpenAI, a private AI company valued at $157 billion']\n",
      " > Processing time: 2.0453603267669678\n",
      " > Real-time factor: 0.19106366165022218\n",
      "Audio generado: output_en_short/4/0.wav\n",
      " > Text splitted to sentences.\n",
      "[\"The investment was spurred by SoftBank's billionaire founder and CEO Masayoshi Son's interest in acquiring a larger stake in the company\"]\n",
      " > Processing time: 2.307343006134033\n",
      " > Real-time factor: 0.18572554642418462\n",
      "Audio generado: output_en_short/4/1.wav\n",
      " > Text splitted to sentences.\n",
      "['The tender offer will allow employees to sell shares at $210 each']\n",
      " > Processing time: 1.2801191806793213\n",
      " > Real-time factor: 0.21659475087460892\n",
      "Audio generado: output_en_short/4/2.wav\n",
      "Audio final guardado en: output_en_short/4/audio_final_4.wav\n",
      "Procesando: 5.txt en output_en_short/5\n",
      "Chunk: Intel has announced the Arc B580 and B570 GPUs, priced at $249 and $219\n",
      "Length: 71\n",
      "\n",
      "Chunk: The Battlemage GPUs feature improved architecture, including SIMD16 ALUs and increased vector and XMX engines,\n",
      "Length: 110\n",
      "\n",
      "Chunk: offering better performance per Xe core\n",
      "Length: 39\n",
      "\n",
      "Chunk: Intel claims the new GPUs offer a net potential improvement of nearly 50% in terms of performance per power consumption\n",
      "Length: 119\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Intel has announced the Arc B580 and B570 GPUs, priced at $249 and $219']\n",
      " > Processing time: 1.9194855690002441\n",
      " > Real-time factor: 0.19290389045274275\n",
      "Audio generado: output_en_short/5/0.wav\n",
      " > Text splitted to sentences.\n",
      "['The Battlemage GPUs feature improved architecture, including SIMD16 ALUs and increased vector and XMX engines,']\n",
      " > Processing time: 1.9629077911376953\n",
      " > Real-time factor: 0.19145957248649134\n",
      "Audio generado: output_en_short/5/1.wav\n",
      " > Text splitted to sentences.\n",
      "['offering better performance per Xe core']\n",
      " > Processing time: 0.927992582321167\n",
      " > Real-time factor: 0.2594623204527\n",
      "Audio generado: output_en_short/5/2.wav\n",
      " > Text splitted to sentences.\n",
      "['Intel claims the new GPUs offer a net potential improvement of nearly 50% in terms of performance per power consumption']\n",
      " > Processing time: 1.7959115505218506\n",
      " > Real-time factor: 0.19855520301347174\n",
      "Audio generado: output_en_short/5/3.wav\n",
      "Audio final guardado en: output_en_short/5/audio_final_5.wav\n",
      "Procesando: 6.txt en output_en_short/6\n",
      "Chunk: MSI's new Claw gaming handhelds promise better battery life, improved ergonomics, and redesigned controls\n",
      "Length: 105\n",
      "\n",
      "Chunk: The Claw 8 AI+ and Claw 7 AI+ boast Lunar Lake processors and promise significant upgrades over their predecessor\n",
      "Length: 113\n",
      "\n",
      "Chunk: The devices feature LCD displays with 120Hz refresh rates and support for CoPilot+ and Thunderbolt 4\n",
      "Length: 100\n",
      "\n",
      " > Text splitted to sentences.\n",
      "[\"MSI's new Claw gaming handhelds promise better battery life, improved ergonomics, and redesigned controls\"]\n",
      " > Processing time: 1.6930315494537354\n",
      " > Real-time factor: 0.20195698988063093\n",
      "Audio generado: output_en_short/6/0.wav\n",
      " > Text splitted to sentences.\n",
      "['The Claw 8 AI+ and Claw 7 AI+ boast Lunar Lake processors and promise significant upgrades over their predecessor']\n",
      " > Processing time: 1.9372608661651611\n",
      " > Real-time factor: 0.19266707304494932\n",
      "Audio generado: output_en_short/6/1.wav\n",
      " > Text splitted to sentences.\n",
      "['The devices feature LCD displays with 120Hz refresh rates and support for CoPilot+ and Thunderbolt 4']\n",
      " > Processing time: 1.6935718059539795\n",
      " > Real-time factor: 0.1960481852230431\n",
      "Audio generado: output_en_short/6/2.wav\n",
      "Audio final guardado en: output_en_short/6/audio_final_6.wav\n",
      "Procesando: 7.txt en output_en_short/7\n",
      "Chunk: PS5 is getting classic themes and boot sequences for PlayStation's 30th anniversary\n",
      "Length: 83\n",
      "\n",
      "Chunk: You can choose dashboard themes inspired by PS1, PS2, PS3, PS4, or a general 30th Anniversary one\n",
      "Length: 97\n",
      "\n",
      "Chunk: But there is a catch   these themes will be available for a limited time\n",
      "Length: 72\n",
      "\n",
      " > Text splitted to sentences.\n",
      "[\"PS5 is getting classic themes and boot sequences for PlayStation's 30th anniversary\"]\n",
      " > Processing time: 1.2997767925262451\n",
      " > Real-time factor: 0.21820622392498862\n",
      "Audio generado: output_en_short/7/0.wav\n",
      " > Text splitted to sentences.\n",
      "['You can choose dashboard themes inspired by PS1, PS2, PS3, PS4, or a general 30th Anniversary one']\n",
      " > Processing time: 1.769937515258789\n",
      " > Real-time factor: 0.1990042537501851\n",
      "Audio generado: output_en_short/7/1.wav\n",
      " > Text splitted to sentences.\n",
      "['But there is a catch   these themes will be available for a limited time']\n",
      " > Processing time: 1.1782939434051514\n",
      " > Real-time factor: 0.2311510805345515\n",
      "Audio generado: output_en_short/7/2.wav\n",
      "Audio final guardado en: output_en_short/7/audio_final_7.wav\n",
      "Procesando: 8.txt en output_en_short/8\n",
      "Chunk: A M D's unreleased Radeon RX 8800 XT graphics card, based on RDNA 4 will have a 220W TDP,\n",
      "Length: 89\n",
      "\n",
      "Chunk: requiring two 8 pin power plugs The graphics card is expected to launch in January 2025\n",
      "Length: 87\n",
      "\n",
      " > Text splitted to sentences.\n",
      "[\"A M D's unreleased Radeon RX 8800 XT graphics card, based on RDNA 4 will have a 220W TDP,\"]\n",
      " > Processing time: 2.1069538593292236\n",
      " > Real-time factor: 0.18961965567740394\n",
      "Audio generado: output_en_short/8/0.wav\n",
      " > Text splitted to sentences.\n",
      "['requiring two 8 pin power plugs The graphics card is expected to launch in January 2025']\n",
      " > Processing time: 1.6248414516448975\n",
      " > Real-time factor: 0.20609614593171874\n",
      "Audio generado: output_en_short/8/1.wav\n",
      "Audio final guardado en: output_en_short/8/audio_final_8.wav\n",
      "Procesando: 9.txt en output_en_short/9\n",
      "Chunk: Apple has launched Apple Music Replay,\n",
      "Length: 38\n",
      "\n",
      "Chunk: a feature that provides users with a recap of their music streaming habits from 2024\n",
      "Length: 84\n",
      "\n",
      "Chunk: This annual recap aims to highlight users' questionable tastes,\n",
      "Length: 63\n",
      "\n",
      "Chunk: but it also raises concerns about the culture of judgment and pressure to conform to certain standards\n",
      "Length: 102\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Apple has launched Apple Music Replay,']\n",
      " > Processing time: 0.9850995540618896\n",
      " > Real-time factor: 0.25323453141979885\n",
      "Audio generado: output_en_short/9/0.wav\n",
      " > Text splitted to sentences.\n",
      "['a feature that provides users with a recap of their music streaming habits from 2024']\n",
      " > Processing time: 1.6070082187652588\n",
      " > Real-time factor: 0.20264051619415063\n",
      "Audio generado: output_en_short/9/1.wav\n",
      " > Text splitted to sentences.\n",
      "[\"This annual recap aims to highlight users' questionable tastes,\"]\n",
      " > Processing time: 1.4158811569213867\n",
      " > Real-time factor: 0.21393062376738142\n",
      "Audio generado: output_en_short/9/2.wav\n",
      " > Text splitted to sentences.\n",
      "['but it also raises concerns about the culture of judgment and pressure to conform to certain standards']\n",
      " > Processing time: 1.4116578102111816\n",
      " > Real-time factor: 0.21329250298183144\n",
      "Audio generado: output_en_short/9/3.wav\n",
      "Audio final guardado en: output_en_short/9/audio_final_9.wav\n",
      "Se procesaron 9 archivos y se generaron carpetas correspondientes en output_en_short.\n"
     ]
    }
   ],
   "source": [
    "# Init TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    new_folder_path = os.path.join(output_path, f'{i+1}')\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "    print(f\"Procesando: {file} en {new_folder_path}\")\n",
    "\n",
    "    # Leer el contenido del archivo .txt\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text_content = f.read()\n",
    "\n",
    "    text = replace_text(text_content, replacements)\n",
    "\n",
    "    # Dividir el texto en fragmentos manejables\n",
    "    separated_input = split_text_into_chunks(text)\n",
    "\n",
    "    # Inicializar lista de clips de audio\n",
    "    all_audio_parts = []\n",
    "\n",
    "    # Generar audios por fragmento\n",
    "    for index, text in enumerate(separated_input):\n",
    "        audio_file_path = os.path.join(new_folder_path, f\"{index}.wav\")\n",
    "        wav_data = tts.tts_to_file(\n",
    "            text=text,\n",
    "            speaker_wav=[f\"{Path_voice}complete/Sample_1.wav\", f\"{Path_voice}Sample#01.wav\", f\"{Path_voice}Sample#06.wav\", f\"{Path_voice}Sample#07.wav\", f\"{Path_voice}Sample#08.wav\", f\"{Path_voice}Sample#09.wav\", f\"{Path_voice}Sample#10.wav\", f\"{Path_voice}Sample#11.wav\", f\"{Path_voice}Sample#13.wav\"],\n",
    "            language=\"en\",\n",
    "            temperature=1,\n",
    "            file_path=audio_file_path\n",
    "        )\n",
    "        print(f\"Audio generado: {audio_file_path}\")\n",
    "        torch.cuda.empty_cache()  # Liberar memoria GPU\n",
    "        audio_part, _ = torchaudio.load(audio_file_path)\n",
    "        all_audio_parts.append(audio_part)\n",
    "\n",
    "    # Concatenar todos los clips de audio\n",
    "    concatenated_audio = torch.cat(all_audio_parts, dim=-1)\n",
    "\n",
    "    # Guardar el audio concatenado\n",
    "    final_audio_path = os.path.join(new_folder_path, f\"audio_final_{i+1}.wav\")\n",
    "    torchaudio.save(final_audio_path, concatenated_audio, sample_rate=24000)\n",
    "    print(f\"Audio final guardado en: {final_audio_path}\")\n",
    "\n",
    "\n",
    "print(f\"Se procesaron {len(files)} archivos y se generaron carpetas correspondientes en {output_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AndTTSCoqui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
