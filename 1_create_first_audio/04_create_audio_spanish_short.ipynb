{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: Your input text here This is an example text to split How does it handle, longer sentences, you may ask? Let's find out!\n",
      "Length: 120\n",
      "\n",
      "Chunk: Your input text here This is an example text to split How does it handle, longer sentences, you may ask? Let's find out!\n",
      "Length: 120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from TTS.api import TTS\n",
    "from time import time\n",
    "from text_split_and import split_text_into_chunks;\n",
    "\n",
    "\n",
    "%run text_split_and.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_replacements(file_path):\n",
    "    \"\"\"Load text replacements from an Excel file.\"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    # df = df[df['langua'] != 'es']\n",
    "    replacements = {}\n",
    "    for index, row in df.iterrows():\n",
    "        replacements[row['original']] = row['replace']\n",
    "    return replacements\n",
    "\n",
    "def replace_text(text, replacements):\n",
    "    \"\"\"Replace text based on a dictionary of replacements.\"\"\"\n",
    "    for original, replace in replacements.items():\n",
    "        text = text.replace(original, replace)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load replacements from Excel file\n",
    "excel_file = 'replaces_words.xlsx'\n",
    "replacements = load_replacements(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ruta donde se deben eliminar las carpetas\n",
    "output_path = 'output_es_short'\n",
    "\n",
    "# Eliminar todas las carpetas en output_path\n",
    "if os.path.exists(output_path):\n",
    "    # Iterar sobre los elementos dentro del directorio\n",
    "    for item in os.listdir(output_path):\n",
    "        item_path = os.path.join(output_path, item)\n",
    "        # Eliminar archivos\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "        # Eliminar carpetas y su contenido de forma recursiva\n",
    "        elif os.path.isdir(item_path):\n",
    "            for root, dirs, files in os.walk(item_path, topdown=False):\n",
    "                for name in files:\n",
    "                    os.remove(os.path.join(root, name))\n",
    "                for name in dirs:\n",
    "                    os.rmdir(os.path.join(root, name))\n",
    "            os.rmdir(item_path)  # Finalmente eliminar la carpeta vacÃ­a\n",
    "else:\n",
    "    print(f\"The folder {output_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que la carpeta exista despuÃ©s de eliminar su contenido\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Ruta de la carpeta de entrada con los archivos .txt\n",
    "folder_path = '/mnt/D8E84E4DE84E2A58/Env_python/Create_video_news/0_create text/text/es/shorts/'\n",
    "\n",
    "# Lista de archivos .txt en la carpeta\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "\n",
    "# Ordenar los archivos si es necesario\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andresmtr/miniconda3/envs/AndTTSCoqui/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: xtts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andresmtr/miniconda3/envs/AndTTSCoqui/lib/python3.9/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.speakers = torch.load(speaker_file_path)\n",
      "/home/andresmtr/miniconda3/envs/AndTTSCoqui/lib/python3.9/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando: 1.txt en output_es_short/1\n",
      "Chunk: Resumen de la semana\n",
      "Length: 20\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Resumen de la semana']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 0.9950864315032959\n",
      " > Real-time factor: 0.3725491682736973\n",
      "Audio generado: output_es_short/1/0.wav\n",
      "Audio final guardado en: output_es_short/1/audio_final_1.wav\n",
      "Procesando: 2.txt en output_es_short/2\n",
      "Chunk: La supuesta GPU Arc B580 de Intel ha aparecido en Geekbench, segÃºn los rumores Cuenta con 20 nÃºcleos Xe,\n",
      "Length: 104\n",
      "\n",
      "Chunk: 12 Gigabyte de BI RAM y un reloj de impulso de 285 GHz Sin embargo, su rendimiento en el benchmark fue decepcionante,\n",
      "Length: 117\n",
      "\n",
      "Chunk: obteniendo solo 78,743 puntos, siendo mÃ¡s lenta que la A580\n",
      "Length: 59\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['La supuesta GPU Arc B580 de Intel ha aparecido en Geekbench, segÃºn los rumores Cuenta con 20 nÃºcleos Xe,']\n",
      " > Processing time: 2.1685121059417725\n",
      " > Real-time factor: 0.19077438531765115\n",
      "Audio generado: output_es_short/2/0.wav\n",
      " > Text splitted to sentences.\n",
      "['12 Gigabyte de BI RAM y un reloj de impulso de 285 GHz Sin embargo, su rendimiento en el benchmark fue decepcionante,']\n",
      " > Processing time: 2.186758518218994\n",
      " > Real-time factor: 0.1866600546869341\n",
      "Audio generado: output_es_short/2/1.wav\n",
      " > Text splitted to sentences.\n",
      "['obteniendo solo 78,743 puntos, siendo mÃ¡s lenta que la A580']\n",
      " > Processing time: 1.749418020248413\n",
      " > Real-time factor: 0.199035475039614\n",
      "Audio generado: output_es_short/2/2.wav\n",
      "Audio final guardado en: output_es_short/2/audio_final_2.wav\n",
      "Procesando: 3.txt en output_es_short/3\n",
      "Chunk: No hay garantÃ­a de que los usuarios obtengan protecciÃ³n de privacidad en la red social Bluesky\n",
      "Length: 94\n",
      "\n",
      "Chunk: Es importante tener en cuenta que cualquier cosa que publiques pÃºblicamente en Bluesky puede ser extraÃ­da o copiada por terceros\n",
      "Length: 128\n",
      "\n",
      "ERROR: Chunk exceeds maximum length!\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['No hay garantÃ­a de que los usuarios obtengan protecciÃ³n de privacidad en la red social Bluesky']\n",
      " > Processing time: 1.3442139625549316\n",
      " > Real-time factor: 0.21125497401596705\n",
      "Audio generado: output_es_short/3/0.wav\n",
      " > Text splitted to sentences.\n",
      "['Es importante tener en cuenta que cualquier cosa que publiques pÃºblicamente en Bluesky puede ser extraÃ­da o copiada por terceros']\n",
      " > Processing time: 1.7392165660858154\n",
      " > Real-time factor: 0.19892587186795707\n",
      "Audio generado: output_es_short/3/1.wav\n",
      "Audio final guardado en: output_es_short/3/audio_final_3.wav\n",
      "Procesando: 4.txt en output_es_short/4\n",
      "Chunk: Raspberry Pi estÃ¡ presentando un nuevo producto, el Compute Module 5\n",
      "Length: 68\n",
      "\n",
      "Chunk: Estas variantes de sistema en mÃ³dulo son computadoras de placa Ãºnica mÃ¡s compactas, sin puertos tradicionales\n",
      "Length: 109\n",
      "\n",
      "Chunk: Esto las hace particularmente adecuadas para aplicaciones integradas\n",
      "Length: 68\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Raspberry Pi estÃ¡ presentando un nuevo producto, el Compute Module 5']\n",
      " > Processing time: 1.2617981433868408\n",
      " > Real-time factor: 0.2173372786345444\n",
      "Audio generado: output_es_short/4/0.wav\n",
      " > Text splitted to sentences.\n",
      "['Estas variantes de sistema en mÃ³dulo son computadoras de placa Ãºnica mÃ¡s compactas, sin puertos tradicionales']\n",
      " > Processing time: 1.6432271003723145\n",
      " > Real-time factor: 0.19254930258486488\n",
      "Audio generado: output_es_short/4/1.wav\n",
      " > Text splitted to sentences.\n",
      "['Esto las hace particularmente adecuadas para aplicaciones integradas']\n",
      " > Processing time: 1.1052076816558838\n",
      " > Real-time factor: 0.22342883031861743\n",
      "Audio generado: output_es_short/4/2.wav\n",
      "Audio final guardado en: output_es_short/4/audio_final_4.wav\n",
      "Procesando: 5.txt en output_es_short/5\n",
      "Chunk: El dispositivo portÃ¡til de Sony probablemente estÃ¡ a aÃ±os de su lanzamiento,\n",
      "Length: 76\n",
      "\n",
      "Chunk: y la compaÃ±Ã­a aÃºn podrÃ­a decidir no sacarlo al mercado,\n",
      "Length: 55\n",
      "\n",
      "Chunk: segÃºn personas que prefirieron no ser identificadas al discutir planes privados Desde el punto de vista del consumidor,\n",
      "Length: 119\n",
      "\n",
      "Chunk: cuantos mÃ¡s dispositivos de este tipo, mejor\n",
      "Length: 44\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['El dispositivo portÃ¡til de Sony probablemente estÃ¡ a aÃ±os de su lanzamiento,']\n",
      " > Processing time: 1.2730591297149658\n",
      " > Real-time factor: 0.21372086894121542\n",
      "Audio generado: output_es_short/5/0.wav\n",
      " > Text splitted to sentences.\n",
      "['y la compaÃ±Ã­a aÃºn podrÃ­a decidir no sacarlo al mercado,']\n",
      " > Processing time: 1.0261013507843018\n",
      " > Real-time factor: 0.2283377884788658\n",
      "Audio generado: output_es_short/5/1.wav\n",
      " > Text splitted to sentences.\n",
      "['segÃºn personas que prefirieron no ser identificadas al discutir planes privados Desde el punto de vista del consumidor,']\n",
      " > Processing time: 1.7849462032318115\n",
      " > Real-time factor: 0.1909695665188138\n",
      "Audio generado: output_es_short/5/2.wav\n",
      " > Text splitted to sentences.\n",
      "['cuantos mÃ¡s dispositivos de este tipo, mejor']\n",
      " > Processing time: 0.9158785343170166\n",
      " > Real-time factor: 0.24570665857614143\n",
      "Audio generado: output_es_short/5/3.wav\n",
      "Audio final guardado en: output_es_short/5/audio_final_5.wav\n",
      "Procesando: 6.txt en output_es_short/6\n",
      "Chunk: Apple estÃ¡ integrando ChatGPT para iOS con la aplicaciÃ³n de Atajos Esto representa una gran mejora,\n",
      "Length: 99\n",
      "\n",
      "Chunk: TambiÃ©n se discutirÃ¡ cÃ³mo esta integraciÃ³n se espera que cambie las interacciones de los usuarios con Siri y otras aplicaciones impulsadas por\n",
      "Length: 142\n",
      "\n",
      "ERROR: Chunk exceeds maximum length!\n",
      "\n",
      "Chunk: inteligencia artificial\n",
      "Length: 23\n",
      "\n",
      "Chunk: ya que la funciÃ³n SearchGPT ofrece la mejor experiencia de bÃºsqueda\n",
      "Length: 67\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Apple estÃ¡ integrando ChatGPT para iOS con la aplicaciÃ³n de Atajos Esto representa una gran mejora,']\n",
      " > Processing time: 1.9576456546783447\n",
      " > Real-time factor: 0.18817607713284465\n",
      "Audio generado: output_es_short/6/0.wav\n",
      " > Text splitted to sentences.\n",
      "['TambiÃ©n se discutirÃ¡ cÃ³mo esta integraciÃ³n se espera que cambie las interacciones de los usuarios con Siri y otras aplicaciones impulsadas por']\n",
      " > Processing time: 1.9377460479736328\n",
      " > Real-time factor: 0.18900532750822158\n",
      "Audio generado: output_es_short/6/1.wav\n",
      " > Text splitted to sentences.\n",
      "['inteligencia artificial']\n",
      " > Processing time: 0.7041547298431396\n",
      " > Real-time factor: 0.29150292492192154\n",
      "Audio generado: output_es_short/6/2.wav\n",
      " > Text splitted to sentences.\n",
      "['ya que la funciÃ³n SearchGPT ofrece la mejor experiencia de bÃºsqueda']\n",
      " > Processing time: 1.2359189987182617\n",
      " > Real-time factor: 0.22037144133893188\n",
      "Audio generado: output_es_short/6/3.wav\n",
      "Audio final guardado en: output_es_short/6/audio_final_6.wav\n",
      "Procesando: 7.txt en output_es_short/7\n",
      "Chunk: El financiamiento de Intel a travÃ©s de la Ley CHIPS ha sido reducido en mÃ¡s de 600 millones de dÃ³lares,\n",
      "Length: 103\n",
      "\n",
      "Chunk: pasando de 85 mil millones a 785 mil millones\n",
      "Length: 45\n",
      "\n",
      "Chunk: La compaÃ±Ã­a planea invertir mÃ¡s de 90 mil millones en Estados Unidos para finales de la dÃ©cada\n",
      "Length: 94\n",
      "\n",
      "Chunk: La administraciÃ³n de Biden estÃ¡ comprometida en apoyar a los fabricantes de chips como Intel y A M D\n",
      "Length: 100\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['El financiamiento de Intel a travÃ©s de la Ley CHIPS ha sido reducido en mÃ¡s de 600 millones de dÃ³lares,']\n",
      " > Processing time: 1.5792291164398193\n",
      " > Real-time factor: 0.1954184363916338\n",
      "Audio generado: output_es_short/7/0.wav\n",
      " > Text splitted to sentences.\n",
      "['pasando de 85 mil millones a 785 mil millones']\n",
      " > Processing time: 1.3056232929229736\n",
      " > Real-time factor: 0.21215801209285143\n",
      "Audio generado: output_es_short/7/1.wav\n",
      " > Text splitted to sentences.\n",
      "['La compaÃ±Ã­a planea invertir mÃ¡s de 90 mil millones en Estados Unidos para finales de la dÃ©cada']\n",
      " > Processing time: 1.42734956741333\n",
      " > Real-time factor: 0.20352468935245685\n",
      "Audio generado: output_es_short/7/2.wav\n",
      " > Text splitted to sentences.\n",
      "['La administraciÃ³n de Biden estÃ¡ comprometida en apoyar a los fabricantes de chips como Intel y A M D']\n",
      " > Processing time: 1.4064385890960693\n",
      " > Real-time factor: 0.20635028005940814\n",
      "Audio generado: output_es_short/7/3.wav\n",
      "Audio final guardado en: output_es_short/7/audio_final_7.wav\n",
      "Procesando: 8.txt en output_es_short/8\n",
      "Chunk: La actualizaciÃ³n de Windows 11 no funciona bien con algunos juegos de Ubisoft\n",
      "Length: 77\n",
      "\n",
      "Chunk: Algunos juegos podrÃ­an volverse inoperativos al iniciar, cargar o durante el juego activo\n",
      "Length: 89\n",
      "\n",
      "Chunk: Los usuarios podrÃ­an recibir una pantalla negra\n",
      "Length: 47\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['La actualizaciÃ³n de Windows 11 no funciona bien con algunos juegos de Ubisoft']\n",
      " > Processing time: 1.3200430870056152\n",
      " > Real-time factor: 0.20898154845256903\n",
      "Audio generado: output_es_short/8/0.wav\n",
      " > Text splitted to sentences.\n",
      "['Algunos juegos podrÃ­an volverse inoperativos al iniciar, cargar o durante el juego activo']\n",
      " > Processing time: 1.4596030712127686\n",
      " > Real-time factor: 0.19672523056382366\n",
      "Audio generado: output_es_short/8/1.wav\n",
      " > Text splitted to sentences.\n",
      "['Los usuarios podrÃ­an recibir una pantalla negra']\n",
      " > Processing time: 0.8354361057281494\n",
      " > Real-time factor: 0.2551153076017296\n",
      "Audio generado: output_es_short/8/2.wav\n",
      "Audio final guardado en: output_es_short/8/audio_final_8.wav\n",
      "Procesando: 9.txt en output_es_short/9\n",
      "Chunk: El Sunday Dragon 3D One de Tencent presenta una enorme pantalla de 11 pulgadas con una tasa de refresco de 120Hz\n",
      "Length: 112\n",
      "\n",
      "Chunk: El dispositivo cuenta con 32 Gigabyte de RAM y 1 Terabyte de almacenamiento,\n",
      "Length: 76\n",
      "\n",
      "Chunk: pero su diseÃ±o ergonÃ³mico plantea dudas sobre su usabilidad como dispositivo portÃ¡til\n",
      "Length: 85\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['El Sunday Dragon 3D One de Tencent presenta una enorme pantalla de 11 pulgadas con una tasa de refresco de 120Hz']\n",
      " > Processing time: 1.8714957237243652\n",
      " > Real-time factor: 0.1930360784565258\n",
      "Audio generado: output_es_short/9/0.wav\n",
      " > Text splitted to sentences.\n",
      "['El dispositivo cuenta con 32 Gigabyte de RAM y 1 Terabyte de almacenamiento,']\n",
      " > Processing time: 1.3359925746917725\n",
      " > Real-time factor: 0.20844161292846133\n",
      "Audio generado: output_es_short/9/1.wav\n",
      " > Text splitted to sentences.\n",
      "['pero su diseÃ±o ergonÃ³mico plantea dudas sobre su usabilidad como dispositivo portÃ¡til']\n",
      " > Processing time: 1.344510793685913\n",
      " > Real-time factor: 0.2097706257838106\n",
      "Audio generado: output_es_short/9/2.wav\n",
      "Audio final guardado en: output_es_short/9/audio_final_9.wav\n",
      "Se procesaron 9 archivos y se generaron carpetas correspondientes en output_es_short.\n"
     ]
    }
   ],
   "source": [
    "# Init TTS\n",
    "\n",
    "tts = TTS(\"xtts\").to(device)\n",
    "# tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    new_folder_path = os.path.join(output_path, f'{i+1}')\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "    print(f\"Procesando: {file} en {new_folder_path}\")\n",
    "\n",
    "    # Leer el contenido del archivo .txt\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text_content = f.read()\n",
    "\n",
    "    text = replace_text(text_content, replacements)\n",
    "\n",
    "    # Dividir el texto en fragmentos manejables\n",
    "    separated_input = split_text_into_chunks(text)\n",
    "\n",
    "    # Inicializar lista de clips de audio\n",
    "    all_audio_parts = []\n",
    "\n",
    "    # Generar audios por fragmento\n",
    "    for index, text in enumerate(separated_input):\n",
    "        audio_file_path = os.path.join(new_folder_path, f\"{index}.wav\")\n",
    "        wav_data = tts.tts_to_file(\n",
    "            text=text,\n",
    "            speaker_wav=\"/mnt/D8E84E4DE84E2A58/Env_python/Machine_learing_Test/0_Create_audio/data/wavs/complete/sample_1.wav\",\n",
    "            language=\"es\",\n",
    "            temperature=0.9,\n",
    "            file_path=audio_file_path\n",
    "        )\n",
    "        print(f\"Audio generado: {audio_file_path}\")\n",
    "        torch.cuda.empty_cache()  # Liberar memoria GPU\n",
    "        audio_part, _ = torchaudio.load(audio_file_path)\n",
    "        all_audio_parts.append(audio_part)\n",
    "\n",
    "    # Concatenar todos los clips de audio\n",
    "    concatenated_audio = torch.cat(all_audio_parts, dim=-1)\n",
    "\n",
    "    # Guardar el audio concatenado\n",
    "    final_audio_path = os.path.join(new_folder_path, f\"audio_final_{i+1}.wav\")\n",
    "    torchaudio.save(final_audio_path, concatenated_audio, sample_rate=24000)\n",
    "    print(f\"Audio final guardado en: {final_audio_path}\")\n",
    "\n",
    "\n",
    "print(f\"Se procesaron {len(files)} archivos y se generaron carpetas correspondientes en {output_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AndTTSCoqui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
