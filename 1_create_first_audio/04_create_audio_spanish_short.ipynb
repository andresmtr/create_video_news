{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: Your input text here This is an example text to split How does it handle, longer sentences, you may ask? Let's find out!\n",
      "Length: 120\n",
      "\n",
      "Chunk: Your input text here This is an example text to split How does it handle, longer sentences, you may ask? Let's find out!\n",
      "Length: 120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from TTS.api import TTS\n",
    "from time import time\n",
    "from text_split_and import split_text_into_chunks;\n",
    "\n",
    "\n",
    "%run text_split_and.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_replacements(file_path):\n",
    "    \"\"\"Load text replacements from an Excel file.\"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    # df = df[df['langua'] != 'es']\n",
    "    replacements = {}\n",
    "    for index, row in df.iterrows():\n",
    "        replacements[row['original']] = row['replace']\n",
    "    return replacements\n",
    "\n",
    "def replace_text(text, replacements):\n",
    "    \"\"\"Replace text based on a dictionary of replacements.\"\"\"\n",
    "    for original, replace in replacements.items():\n",
    "        text = text.replace(original, replace)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load replacements from Excel file\n",
    "excel_file = 'replaces_words.xlsx'\n",
    "replacements = load_replacements(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ruta donde se deben eliminar las carpetas\n",
    "output_path = 'output_es_short'\n",
    "\n",
    "# Eliminar todas las carpetas en output_path\n",
    "if os.path.exists(output_path):\n",
    "    # Iterar sobre los elementos dentro del directorio\n",
    "    for item in os.listdir(output_path):\n",
    "        item_path = os.path.join(output_path, item)\n",
    "        # Eliminar archivos\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "        # Eliminar carpetas y su contenido de forma recursiva\n",
    "        elif os.path.isdir(item_path):\n",
    "            for root, dirs, files in os.walk(item_path, topdown=False):\n",
    "                for name in files:\n",
    "                    os.remove(os.path.join(root, name))\n",
    "                for name in dirs:\n",
    "                    os.rmdir(os.path.join(root, name))\n",
    "            os.rmdir(item_path)  # Finalmente eliminar la carpeta vac칤a\n",
    "else:\n",
    "    print(f\"The folder {output_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que la carpeta exista despu칠s de eliminar su contenido\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Ruta de la carpeta de entrada con los archivos .txt\n",
    "folder_path = '/mnt/D8E84E4DE84E2A58/Env_python/Create_video_news/0_create text/text/es/shorts/'\n",
    "\n",
    "# Lista de archivos .txt en la carpeta\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "\n",
    "# Ordenar los archivos si es necesario\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andresmtr/miniconda3/envs/AndTTSCoqui/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: xtts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andresmtr/miniconda3/envs/AndTTSCoqui/lib/python3.9/site-packages/TTS/tts/layers/xtts/xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.speakers = torch.load(speaker_file_path)\n",
      "/home/andresmtr/miniconda3/envs/AndTTSCoqui/lib/python3.9/site-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 游녤v4.50游녣 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando: 1.txt en output_es_short/1\n",
      "Chunk: Resumen de la semana\n",
      "Length: 20\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Resumen de la semana']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Processing time: 0.9950864315032959\n",
      " > Real-time factor: 0.3725491682736973\n",
      "Audio generado: output_es_short/1/0.wav\n",
      "Audio final guardado en: output_es_short/1/audio_final_1.wav\n",
      "Procesando: 2.txt en output_es_short/2\n",
      "Chunk: La supuesta GPU Arc B580 de Intel ha aparecido en Geekbench, seg칰n los rumores Cuenta con 20 n칰cleos Xe,\n",
      "Length: 104\n",
      "\n",
      "Chunk: 12 Gigabyte de BI RAM y un reloj de impulso de 285 GHz Sin embargo, su rendimiento en el benchmark fue decepcionante,\n",
      "Length: 117\n",
      "\n",
      "Chunk: obteniendo solo 78,743 puntos, siendo m치s lenta que la A580\n",
      "Length: 59\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['La supuesta GPU Arc B580 de Intel ha aparecido en Geekbench, seg칰n los rumores Cuenta con 20 n칰cleos Xe,']\n",
      " > Processing time: 2.1685121059417725\n",
      " > Real-time factor: 0.19077438531765115\n",
      "Audio generado: output_es_short/2/0.wav\n",
      " > Text splitted to sentences.\n",
      "['12 Gigabyte de BI RAM y un reloj de impulso de 285 GHz Sin embargo, su rendimiento en el benchmark fue decepcionante,']\n",
      " > Processing time: 2.186758518218994\n",
      " > Real-time factor: 0.1866600546869341\n",
      "Audio generado: output_es_short/2/1.wav\n",
      " > Text splitted to sentences.\n",
      "['obteniendo solo 78,743 puntos, siendo m치s lenta que la A580']\n",
      " > Processing time: 1.749418020248413\n",
      " > Real-time factor: 0.199035475039614\n",
      "Audio generado: output_es_short/2/2.wav\n",
      "Audio final guardado en: output_es_short/2/audio_final_2.wav\n",
      "Procesando: 3.txt en output_es_short/3\n",
      "Chunk: No hay garant칤a de que los usuarios obtengan protecci칩n de privacidad en la red social Bluesky\n",
      "Length: 94\n",
      "\n",
      "Chunk: Es importante tener en cuenta que cualquier cosa que publiques p칰blicamente en Bluesky puede ser extra칤da o copiada por terceros\n",
      "Length: 128\n",
      "\n",
      "ERROR: Chunk exceeds maximum length!\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['No hay garant칤a de que los usuarios obtengan protecci칩n de privacidad en la red social Bluesky']\n",
      " > Processing time: 1.3442139625549316\n",
      " > Real-time factor: 0.21125497401596705\n",
      "Audio generado: output_es_short/3/0.wav\n",
      " > Text splitted to sentences.\n",
      "['Es importante tener en cuenta que cualquier cosa que publiques p칰blicamente en Bluesky puede ser extra칤da o copiada por terceros']\n",
      " > Processing time: 1.7392165660858154\n",
      " > Real-time factor: 0.19892587186795707\n",
      "Audio generado: output_es_short/3/1.wav\n",
      "Audio final guardado en: output_es_short/3/audio_final_3.wav\n",
      "Procesando: 4.txt en output_es_short/4\n",
      "Chunk: Raspberry Pi est치 presentando un nuevo producto, el Compute Module 5\n",
      "Length: 68\n",
      "\n",
      "Chunk: Estas variantes de sistema en m칩dulo son computadoras de placa 칰nica m치s compactas, sin puertos tradicionales\n",
      "Length: 109\n",
      "\n",
      "Chunk: Esto las hace particularmente adecuadas para aplicaciones integradas\n",
      "Length: 68\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Raspberry Pi est치 presentando un nuevo producto, el Compute Module 5']\n",
      " > Processing time: 1.2617981433868408\n",
      " > Real-time factor: 0.2173372786345444\n",
      "Audio generado: output_es_short/4/0.wav\n",
      " > Text splitted to sentences.\n",
      "['Estas variantes de sistema en m칩dulo son computadoras de placa 칰nica m치s compactas, sin puertos tradicionales']\n",
      " > Processing time: 1.6432271003723145\n",
      " > Real-time factor: 0.19254930258486488\n",
      "Audio generado: output_es_short/4/1.wav\n",
      " > Text splitted to sentences.\n",
      "['Esto las hace particularmente adecuadas para aplicaciones integradas']\n",
      " > Processing time: 1.1052076816558838\n",
      " > Real-time factor: 0.22342883031861743\n",
      "Audio generado: output_es_short/4/2.wav\n",
      "Audio final guardado en: output_es_short/4/audio_final_4.wav\n",
      "Procesando: 5.txt en output_es_short/5\n",
      "Chunk: El dispositivo port치til de Sony probablemente est치 a a침os de su lanzamiento,\n",
      "Length: 76\n",
      "\n",
      "Chunk: y la compa침칤a a칰n podr칤a decidir no sacarlo al mercado,\n",
      "Length: 55\n",
      "\n",
      "Chunk: seg칰n personas que prefirieron no ser identificadas al discutir planes privados Desde el punto de vista del consumidor,\n",
      "Length: 119\n",
      "\n",
      "Chunk: cuantos m치s dispositivos de este tipo, mejor\n",
      "Length: 44\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['El dispositivo port치til de Sony probablemente est치 a a침os de su lanzamiento,']\n",
      " > Processing time: 1.2730591297149658\n",
      " > Real-time factor: 0.21372086894121542\n",
      "Audio generado: output_es_short/5/0.wav\n",
      " > Text splitted to sentences.\n",
      "['y la compa침칤a a칰n podr칤a decidir no sacarlo al mercado,']\n",
      " > Processing time: 1.0261013507843018\n",
      " > Real-time factor: 0.2283377884788658\n",
      "Audio generado: output_es_short/5/1.wav\n",
      " > Text splitted to sentences.\n",
      "['seg칰n personas que prefirieron no ser identificadas al discutir planes privados Desde el punto de vista del consumidor,']\n",
      " > Processing time: 1.7849462032318115\n",
      " > Real-time factor: 0.1909695665188138\n",
      "Audio generado: output_es_short/5/2.wav\n",
      " > Text splitted to sentences.\n",
      "['cuantos m치s dispositivos de este tipo, mejor']\n",
      " > Processing time: 0.9158785343170166\n",
      " > Real-time factor: 0.24570665857614143\n",
      "Audio generado: output_es_short/5/3.wav\n",
      "Audio final guardado en: output_es_short/5/audio_final_5.wav\n",
      "Procesando: 6.txt en output_es_short/6\n",
      "Chunk: Apple est치 integrando ChatGPT para iOS con la aplicaci칩n de Atajos Esto representa una gran mejora,\n",
      "Length: 99\n",
      "\n",
      "Chunk: Tambi칠n se discutir치 c칩mo esta integraci칩n se espera que cambie las interacciones de los usuarios con Siri y otras aplicaciones impulsadas por\n",
      "Length: 142\n",
      "\n",
      "ERROR: Chunk exceeds maximum length!\n",
      "\n",
      "Chunk: inteligencia artificial\n",
      "Length: 23\n",
      "\n",
      "Chunk: ya que la funci칩n SearchGPT ofrece la mejor experiencia de b칰squeda\n",
      "Length: 67\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['Apple est치 integrando ChatGPT para iOS con la aplicaci칩n de Atajos Esto representa una gran mejora,']\n",
      " > Processing time: 1.9576456546783447\n",
      " > Real-time factor: 0.18817607713284465\n",
      "Audio generado: output_es_short/6/0.wav\n",
      " > Text splitted to sentences.\n",
      "['Tambi칠n se discutir치 c칩mo esta integraci칩n se espera que cambie las interacciones de los usuarios con Siri y otras aplicaciones impulsadas por']\n",
      " > Processing time: 1.9377460479736328\n",
      " > Real-time factor: 0.18900532750822158\n",
      "Audio generado: output_es_short/6/1.wav\n",
      " > Text splitted to sentences.\n",
      "['inteligencia artificial']\n",
      " > Processing time: 0.7041547298431396\n",
      " > Real-time factor: 0.29150292492192154\n",
      "Audio generado: output_es_short/6/2.wav\n",
      " > Text splitted to sentences.\n",
      "['ya que la funci칩n SearchGPT ofrece la mejor experiencia de b칰squeda']\n",
      " > Processing time: 1.2359189987182617\n",
      " > Real-time factor: 0.22037144133893188\n",
      "Audio generado: output_es_short/6/3.wav\n",
      "Audio final guardado en: output_es_short/6/audio_final_6.wav\n",
      "Procesando: 7.txt en output_es_short/7\n",
      "Chunk: El financiamiento de Intel a trav칠s de la Ley CHIPS ha sido reducido en m치s de 600 millones de d칩lares,\n",
      "Length: 103\n",
      "\n",
      "Chunk: pasando de 85 mil millones a 785 mil millones\n",
      "Length: 45\n",
      "\n",
      "Chunk: La compa침칤a planea invertir m치s de 90 mil millones en Estados Unidos para finales de la d칠cada\n",
      "Length: 94\n",
      "\n",
      "Chunk: La administraci칩n de Biden est치 comprometida en apoyar a los fabricantes de chips como Intel y A M D\n",
      "Length: 100\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['El financiamiento de Intel a trav칠s de la Ley CHIPS ha sido reducido en m치s de 600 millones de d칩lares,']\n",
      " > Processing time: 1.5792291164398193\n",
      " > Real-time factor: 0.1954184363916338\n",
      "Audio generado: output_es_short/7/0.wav\n",
      " > Text splitted to sentences.\n",
      "['pasando de 85 mil millones a 785 mil millones']\n",
      " > Processing time: 1.3056232929229736\n",
      " > Real-time factor: 0.21215801209285143\n",
      "Audio generado: output_es_short/7/1.wav\n",
      " > Text splitted to sentences.\n",
      "['La compa침칤a planea invertir m치s de 90 mil millones en Estados Unidos para finales de la d칠cada']\n",
      " > Processing time: 1.42734956741333\n",
      " > Real-time factor: 0.20352468935245685\n",
      "Audio generado: output_es_short/7/2.wav\n",
      " > Text splitted to sentences.\n",
      "['La administraci칩n de Biden est치 comprometida en apoyar a los fabricantes de chips como Intel y A M D']\n",
      " > Processing time: 1.4064385890960693\n",
      " > Real-time factor: 0.20635028005940814\n",
      "Audio generado: output_es_short/7/3.wav\n",
      "Audio final guardado en: output_es_short/7/audio_final_7.wav\n",
      "Procesando: 8.txt en output_es_short/8\n",
      "Chunk: La actualizaci칩n de Windows 11 no funciona bien con algunos juegos de Ubisoft\n",
      "Length: 77\n",
      "\n",
      "Chunk: Algunos juegos podr칤an volverse inoperativos al iniciar, cargar o durante el juego activo\n",
      "Length: 89\n",
      "\n",
      "Chunk: Los usuarios podr칤an recibir una pantalla negra\n",
      "Length: 47\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['La actualizaci칩n de Windows 11 no funciona bien con algunos juegos de Ubisoft']\n",
      " > Processing time: 1.3200430870056152\n",
      " > Real-time factor: 0.20898154845256903\n",
      "Audio generado: output_es_short/8/0.wav\n",
      " > Text splitted to sentences.\n",
      "['Algunos juegos podr칤an volverse inoperativos al iniciar, cargar o durante el juego activo']\n",
      " > Processing time: 1.4596030712127686\n",
      " > Real-time factor: 0.19672523056382366\n",
      "Audio generado: output_es_short/8/1.wav\n",
      " > Text splitted to sentences.\n",
      "['Los usuarios podr칤an recibir una pantalla negra']\n",
      " > Processing time: 0.8354361057281494\n",
      " > Real-time factor: 0.2551153076017296\n",
      "Audio generado: output_es_short/8/2.wav\n",
      "Audio final guardado en: output_es_short/8/audio_final_8.wav\n",
      "Procesando: 9.txt en output_es_short/9\n",
      "Chunk: El Sunday Dragon 3D One de Tencent presenta una enorme pantalla de 11 pulgadas con una tasa de refresco de 120Hz\n",
      "Length: 112\n",
      "\n",
      "Chunk: El dispositivo cuenta con 32 Gigabyte de RAM y 1 Terabyte de almacenamiento,\n",
      "Length: 76\n",
      "\n",
      "Chunk: pero su dise침o ergon칩mico plantea dudas sobre su usabilidad como dispositivo port치til\n",
      "Length: 85\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['El Sunday Dragon 3D One de Tencent presenta una enorme pantalla de 11 pulgadas con una tasa de refresco de 120Hz']\n",
      " > Processing time: 1.8714957237243652\n",
      " > Real-time factor: 0.1930360784565258\n",
      "Audio generado: output_es_short/9/0.wav\n",
      " > Text splitted to sentences.\n",
      "['El dispositivo cuenta con 32 Gigabyte de RAM y 1 Terabyte de almacenamiento,']\n",
      " > Processing time: 1.3359925746917725\n",
      " > Real-time factor: 0.20844161292846133\n",
      "Audio generado: output_es_short/9/1.wav\n",
      " > Text splitted to sentences.\n",
      "['pero su dise침o ergon칩mico plantea dudas sobre su usabilidad como dispositivo port치til']\n",
      " > Processing time: 1.344510793685913\n",
      " > Real-time factor: 0.2097706257838106\n",
      "Audio generado: output_es_short/9/2.wav\n",
      "Audio final guardado en: output_es_short/9/audio_final_9.wav\n",
      "Se procesaron 9 archivos y se generaron carpetas correspondientes en output_es_short.\n"
     ]
    }
   ],
   "source": [
    "# Init TTS\n",
    "\n",
    "tts = TTS(\"xtts\").to(device)\n",
    "# tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    new_folder_path = os.path.join(output_path, f'{i+1}')\n",
    "    os.makedirs(new_folder_path, exist_ok=True)\n",
    "    print(f\"Procesando: {file} en {new_folder_path}\")\n",
    "\n",
    "    # Leer el contenido del archivo .txt\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text_content = f.read()\n",
    "\n",
    "    text = replace_text(text_content, replacements)\n",
    "\n",
    "    # Dividir el texto en fragmentos manejables\n",
    "    separated_input = split_text_into_chunks(text)\n",
    "\n",
    "    # Inicializar lista de clips de audio\n",
    "    all_audio_parts = []\n",
    "\n",
    "    # Generar audios por fragmento\n",
    "    for index, text in enumerate(separated_input):\n",
    "        audio_file_path = os.path.join(new_folder_path, f\"{index}.wav\")\n",
    "        wav_data = tts.tts_to_file(\n",
    "            text=text,\n",
    "            speaker_wav=\"/mnt/D8E84E4DE84E2A58/Env_python/Machine_learing_Test/0_Create_audio/data/wavs/complete/sample_1.wav\",\n",
    "            language=\"es\",\n",
    "            temperature=0.9,\n",
    "            file_path=audio_file_path\n",
    "        )\n",
    "        print(f\"Audio generado: {audio_file_path}\")\n",
    "        torch.cuda.empty_cache()  # Liberar memoria GPU\n",
    "        audio_part, _ = torchaudio.load(audio_file_path)\n",
    "        all_audio_parts.append(audio_part)\n",
    "\n",
    "    # Concatenar todos los clips de audio\n",
    "    concatenated_audio = torch.cat(all_audio_parts, dim=-1)\n",
    "\n",
    "    # Guardar el audio concatenado\n",
    "    final_audio_path = os.path.join(new_folder_path, f\"audio_final_{i+1}.wav\")\n",
    "    torchaudio.save(final_audio_path, concatenated_audio, sample_rate=24000)\n",
    "    print(f\"Audio final guardado en: {final_audio_path}\")\n",
    "\n",
    "\n",
    "print(f\"Se procesaron {len(files)} archivos y se generaron carpetas correspondientes en {output_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AndTTSCoqui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
